{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datacube\n",
    "dc = datacube.Datacube()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>time_min</th>\n",
       "      <th>time_max</th>\n",
       "      <th>fire_date</th>\n",
       "      <th>sensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BlackSaturday</th>\n",
       "      <td>145.0000</td>\n",
       "      <td>145.9000</td>\n",
       "      <td>-37.2000</td>\n",
       "      <td>-37.7000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2009-12</td>\n",
       "      <td>2009-02-07</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tas2016_Central_Plateau</th>\n",
       "      <td>146.0852</td>\n",
       "      <td>146.3702</td>\n",
       "      <td>-41.5985</td>\n",
       "      <td>-41.7314</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tas2016_Sumac_Forest</th>\n",
       "      <td>144.6893</td>\n",
       "      <td>145.1582</td>\n",
       "      <td>-41.0711</td>\n",
       "      <td>-41.3711</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MtCanobolas</th>\n",
       "      <td>148.9419</td>\n",
       "      <td>149.0322</td>\n",
       "      <td>-33.3014</td>\n",
       "      <td>-33.3882</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>2018-02-10</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoyalNationalPark</th>\n",
       "      <td>150.8749</td>\n",
       "      <td>151.1500</td>\n",
       "      <td>-34.0713</td>\n",
       "      <td>-34.2570</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MtDavidStateForest</th>\n",
       "      <td>149.4000</td>\n",
       "      <td>149.6750</td>\n",
       "      <td>-33.7000</td>\n",
       "      <td>-33.9300</td>\n",
       "      <td>2003-01</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          lon_min   lon_max  lat_min  lat_max time_min  \\\n",
       "EventName                                                                \n",
       "BlackSaturday            145.0000  145.9000 -37.2000 -37.7000  2000-01   \n",
       "Tas2016_Central_Plateau  146.0852  146.3702 -41.5985 -41.7314  2013-01   \n",
       "Tas2016_Sumac_Forest     144.6893  145.1582 -41.0711 -41.3711  2013-01   \n",
       "MtCanobolas              148.9419  149.0322 -33.3014 -33.3882  2013-01   \n",
       "RoyalNationalPark        150.8749  151.1500 -34.0713 -34.2570  2013-01   \n",
       "MtDavidStateForest       149.4000  149.6750 -33.7000 -33.9300  2003-01   \n",
       "\n",
       "                        time_max   fire_date sensor  \n",
       "EventName                                            \n",
       "BlackSaturday            2009-12  2009-02-07    ls5  \n",
       "Tas2016_Central_Plateau  2018-01  2016-02-08    ls8  \n",
       "Tas2016_Sumac_Forest     2018-01  2016-02-08    ls8  \n",
       "MtCanobolas              2018-12  2018-02-10    ls8  \n",
       "RoyalNationalPark        2018-12  2018-01-20    ls8  \n",
       "MtDavidStateForest       2018-01  2014-01-18    ls8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_events = pd.read_csv('fire_events.csv', index_col=0)\n",
    "fire_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Reflectance():\n",
    "    \"\"\"This calls the dc.load function on the NBAR reflectance product.\n",
    "    This uses the sensor specified in the 'fire_events.csv' file.\"\"\"\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    reflectance = dc.load( product=  sensor + '_nbar_albers', \n",
    "               x=lon_extent, \n",
    "               y=lat_extent,\n",
    "               time = time_bounds,\n",
    "               resolution = (-100,100)\n",
    "               , dask_chunks = {'time': 5}\n",
    "                     )\n",
    "\n",
    "    reflectance = reflectance.where((reflectance != -999))\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print (\"reflectance loading took: \", (end_time - start_time))\n",
    "    print (\"reflectance: \", (reflectance).nbytes / 10**9 , \"GB\")\n",
    "\n",
    "    return (reflectance)\n",
    "\n",
    "\n",
    "def _get_Pixel_Quality():\n",
    "    \"\"\"This calls the dc.load function on the pixel quality product.\n",
    "    This uses the sensor specified in the 'fire_events.csv' file.\"\"\"\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    pq = dc.load( product=  sensor + '_pq_albers', \n",
    "           x=lon_extent, \n",
    "           y=lat_extent,\n",
    "           time = time_bounds,\n",
    "           resolution = (-100,100)\n",
    "           , dask_chunks = {'time': 5}\n",
    "                     )\n",
    "    end_time = datetime.datetime.now()\n",
    "\n",
    "    # This next chunk creates a cloud_mask using the datacube masking methods\n",
    "    from datacube.storage import masking\n",
    "    cloud_mask = masking.make_mask(pq, \n",
    "        cloud_acca='no_cloud', cloud_fmask='no_cloud',\n",
    "        cloud_shadow_acca = 'no_cloud_shadow', cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "        contiguous=True #, land_sea = 'land'\n",
    "        ).pixelquality\n",
    "    \n",
    "    print (\"cloud mask loading took: \", (end_time - start_time))\n",
    "    print (\"cloud mask: \", (cloud_mask).nbytes / 10**9 , \"GB\")\n",
    "    return cloud_mask\n",
    "\n",
    "\n",
    "def _plot_RGB(xarray_dataset = None):\n",
    "    rgb = xarray_dataset[['red','green','blue']]\n",
    "    rgb = rgb.to_array(dim='color',name=None)\n",
    "    \n",
    "    fake_saturation = 2000\n",
    "    \n",
    "    rgb = rgb.transpose(*(rgb.dims[1:]+rgb.dims[:1]))  # make 'color' the last dimension\n",
    "    rgb = rgb.where((rgb <= fake_saturation).all(dim='color'))  # mask out pixels where any band is 'saturated'\n",
    "    rgb /= fake_saturation  # scale to [0, 1] range for imshow\n",
    "    rgb.plot.imshow(x='x',y='y', col='time', col_wrap=5, add_colorbar=False)\n",
    "\n",
    "    \n",
    "def _get_unique_dates(times = None):\n",
    "    times = pd.to_datetime(times)\n",
    "    \n",
    "    #times = times.date\n",
    "    for step in range(0,len(times)-1):\n",
    "        try:\n",
    "            if times.date[step] == times.date[step+1]:\n",
    "                times = np.delete(times,step)\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    times = times.values\n",
    "    times = pd.to_datetime(times).date.astype(np.datetime64)\n",
    "        \n",
    "    return(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = 'MtDavidStateForest'     #ENTER HERE\n",
    "name = (fire_events[fire_events.index==event_name].index.values[0] ) \n",
    "lat_extent = ( fire_events[fire_events.index==event_name].lat_min.values[0] ,\n",
    "                   fire_events[fire_events.index==event_name].lat_max.values[0] )\n",
    "lon_extent = ( fire_events[fire_events.index==event_name].lon_min.values[0] ,\n",
    "                   fire_events[fire_events.index==event_name].lon_max.values[0] )\n",
    "time_bounds = ( fire_events[fire_events.index==event_name].time_min.values[0] ,\n",
    "                   fire_events[fire_events.index==event_name].time_max.values[0] )\n",
    "\n",
    "#sensor = fire_events[fire_events.index==event_name].sensor.values[0]\n",
    "\n",
    "#time_bounds = (np.datetime64('2017-07') , np.datetime64('2018-12'))\n",
    "sensor = 'ls5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reflectance loading took:  0:00:23.142196\n",
      "reflectance:  1.41733744 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".resample() has been modified to defer calculations. Instead of passing 'dim' and 'how=\"mean\", instead consider using .resample(time=\"D\").mean() \n",
      "  \n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/xarray/core/common.py:619: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  label=label, base=base)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud mask loading took:  0:00:08.320960\n",
      "cloud mask:  0.029527708 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".resample() has been modified to defer calculations. Instead of passing 'dim' and 'how=\"mean\", instead consider using .resample(time=\"D\").mean() \n",
      "  \"\"\"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/xarray/core/common.py:619: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  label=label, base=base)\n"
     ]
    }
   ],
   "source": [
    "A = _get_Reflectance()\n",
    "A = A.resample(freq='D', dim = 'time', how='mean', keep_attrs=True).sel(time= _get_unique_dates(A.time.values) )\n",
    "\n",
    "B = _get_Pixel_Quality()\n",
    "B = B.resample(freq='D', dim = 'time', how='mean', keep_attrs=True).sel(time= _get_unique_dates(B.time.values) )\n",
    "\n",
    "\n",
    "if sensor == 'ls5':\n",
    "    variables = ['blue','green','red','nir','swir1','swir2']\n",
    "else:\n",
    "    variables = ['coastal_aerosol','blue','green','red','nir','swir1','swir2']\n",
    "    \n",
    "for i in variables:\n",
    "    A[i].attrs['units'] = '1'\n",
    "A.time.attrs['units'] = 'seconds since 1970-01-01 00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/dask/array/numpy_compat.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    }
   ],
   "source": [
    "datacube.storage.storage.write_dataset_to_netcdf(A, ('%s_NBAR_%s.nc') % (name, sensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/dask/array/numpy_compat.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    }
   ],
   "source": [
    "C = A.where(\n",
    "    B.isel(time = B.sum(dim=('x','y'))/(len(B.x)*len(B.y)) > 0.1) # Cloud_masked, with frames less than 10% coverage dropped\n",
    "       )\n",
    "\n",
    "datacube.storage.storage.write_dataset_to_netcdf(C, ('%s_NBAR_cloudmasked_%s.nc') % (name, sensor))\n",
    "del(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
